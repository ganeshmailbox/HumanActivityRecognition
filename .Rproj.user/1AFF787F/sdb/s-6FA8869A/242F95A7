{
    "contents" : "\n\n\n### QUIZ 1\nlibrary(dplyr)\ntbl = tbl_df(df) ## change this to do real smartfly data\nfileUrl <- \"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv\"\ndownload.file(fileUrl, \"getdata.csv\")\ndf <-read.csv(\"getdata.csv\", header=TRUE)\n\n#Q3:\n    library(xlsx)\ncolIndex <- 7:15\n    rowIndex <- 18:23\n    \n    dat <- read.xlsx(\"getdata-data-DATA.gov_NGAP.xlsx\", sheetIndex=1, colIndex=colIndex, rowIndex=rowIndex )\n    sum(dat$Zip*dat$Ext,na.rm=T) \n#Q4:\n    library(XML)\n    fileUrl <- \"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml\"\n    fileURL2 <- sub('https', 'http', fileUrl)\n    \n    download.file(fileUrl, \"getdataResturent.xml\")\n    doc <- xmlTreeParse(fileURL2,useInternal = TRUE)\n    rootNode <- xmlRoot(doc)\n    names(rootNode)\nxmlName(rootNode)\n    vec <- xpathSApply(rootNode,\"//zipcode\",xmlValue)\n    which(vec == \"21231\")\n    \n    length(which(vec == \"21231\"))\n\n### WEEK 2 Quiz\n    library(XML)\n    \n    fileUrl <- \"http://biostat.jhsph.edu/~jleek/contact.html\"\n    download.file(fileUrl, \"contact.html\")\n    html<-readLines(\"contact.html\")\n    nchar(html[10])\n    nchar(html[20])\n    nchar(html[30])\n    nchar(html[100])\n\n    library(utils)\n    \n    fileUrl <- \"https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for\"\n    download.file(fileUrl, \"getdatawksst.for\")\n    da <- read.fwf(\"getdatawksst.for\", widths = c(15,4,9,4,9,4,9,4,4),skip=4)  \n    sum(da$V4)\n    \n### Quiz 3 - Week\n## 1\n        library(\"dplyr\")\n    fileUrl <- \"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv\"\n    download.file(fileUrl, \"getdatFss.csv\")\n    df <-read.csv(\"getdatFss.csv\", header=TRUE)\n    #df <- tbl_df(df) \n    agricultureLogical  <- df %>% mutate(logi = (AGS == 6 & ACR == 3)) %>% select(logi)\n    which(agricultureLogical$logi == TRUE)\n    head(df[which(agricultureLogical$logi == TRUE),])\n    class(agricultureLogical$logi)\n    agricultureLogical$logi[5]\n    agricultureLogical$logi[621]\n    \n    which(agricultureLogical$logi == TRUE)\n## 2\n    fileUrl <- \"https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg\"\n    download.file(fileUrl, \"getdatajeff.jpg\",mode=\"wb\")\n    #install.packages(\"jpeg\") \n    install.packages(\"spatstat\") \n    library(jpeg)\n    library(spatstat)\n    img <- readJPEG(\"getdatajeff.jpg\", native=TRUE)\n    quantile(img, c(.30, .80))\n    \n## 3\n    fileUrl1 <- \"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv\"\n    fileUrl2 <- \"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv\"\n    download.file(fileUrl1, \"getdatagdp.csv\")\n    download.file(fileUrl2, \"getdataFEDCountry.csv\")\n    write.csv(file2, \"getdatagdp1.csv\")\n    df1 <-read.csv(\"getdatagdp.csv\", header=FALSE, skip=5,col.names = c(\"CountryCode\",\"Ranking\",\"Dummy\",\"Economy\",\"USD\",\"1\",\"2\",\"3\",\"4\",\"5\"))\n    a <- nrow(df1) \n    df1n <- df1[1:190,]\n    df1n <- transform(df1n, Ranking = as.integer(as.character(Ranking)))\n    \n    df2 <-read.csv(\"getdataFEDCountry.csv\", header=TRUE, blank.lines.skip = TRUE)\n    mergedData <- merge(df1n, df2, by.x = \"CountryCode\", by.y = \"CountryCode\", sort = FALSE)\n    mergedDataO <- mergedData %>% arrange(desc(Ranking))\n\n## 4\n    df3 <- mergedDataO %>% filter (Income.Group ==  \"High income: OECD\" |  Income.Group ==  \"High income: nonOECD\") %>% group_by(Income.Group) %>% summarise(mean(Ranking))\n\n## 5\n    install.packages(\"Hmisc\")\n    library(\"Hmisc\")\n    mergedDataO$rankingGroups <- cut2(mergedDataO$Ranking, g = 5)\n    table(mergedDataO$rankingGroups, mergedDataO$Income.Group)\n    ",
    "created" : 1424582363477.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "957050915",
    "id" : "242F95A7",
    "lastKnownWriteTime" : 1424500612,
    "path" : "C:/Ganesh/Works/CS3-GetCleanData/quiz.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "type" : "r_source"
}